// Live Recording Example: Real-time transcription with NATS
//
// This example demonstrates the complete Week 3 pipeline:
// 1. ScreenCaptureKit captures system audio + microphone (Swift-based mixing)
// 2. Audio is downsampled from 48kHz stereo to 16kHz mono for Whisper
// 3. Frames are published to NATS
// 4. loqa-core (Whisper) transcribes and publishes results back
// 5. We listen and display transcripts in real-time
//
// IMPORTANT: Requires macOS permissions:
// - System Settings â†’ Privacy & Security â†’ Screen Recording â†’ Add Terminal/IDE
// - System Settings â†’ Privacy & Security â†’ Microphone â†’ Add Terminal/IDE
//
// Prerequisites:
// - NATS server running: docker run -p 4222:4222 nats
// - loqa-core STT service running: cd loqa-core && cargo run
//
// Usage: cargo run --example live_transcription

use anyhow::Result;
use futures::stream::StreamExt;
use loqa_meetings::{AudioBackendConfig, AudioBackendFactory, AudioFrame, AudioSource, NatsClient, TranscriptMessage};
use std::sync::atomic::{AtomicBool, Ordering};
use std::sync::Arc;
use std::time::Duration;
use tokio::time::{sleep, timeout};
use tracing::info;

/// Simple downsampling by decimation (takes every Nth sample)
/// Converts 48kHz stereo to 16kHz stereo
fn downsample_frame(frame: AudioFrame, target_rate: u32) -> AudioFrame {
    if frame.sample_rate == target_rate {
        return frame; // Already at target rate
    }

    let ratio = frame.sample_rate / target_rate;
    if ratio <= 1 {
        return frame; // Can't upsample, return as-is
    }

    // Decimate: take every Nth sample
    let downsampled: Vec<i16> = frame
        .samples
        .iter()
        .step_by(ratio as usize)
        .copied()
        .collect();

    AudioFrame {
        samples: downsampled,
        sample_rate: target_rate,
        channels: frame.channels,
        timestamp_ms: frame.timestamp_ms,
        source: frame.source,
    }
}

/// Convert stereo to mono by averaging left and right channels
/// Input samples are interleaved: [L, R, L, R, ...]
/// Output is mono: [M, M, M, ...]
fn stereo_to_mono(frame: AudioFrame) -> AudioFrame {
    if frame.channels == 1 {
        return frame; // Already mono
    }

    if frame.channels != 2 {
        // Only support stereo -> mono conversion
        return frame;
    }

    let mut mono_samples = Vec::with_capacity(frame.samples.len() / 2);

    // Process pairs of samples (left, right)
    for chunk in frame.samples.chunks_exact(2) {
        let left = chunk[0] as i32;
        let right = chunk[1] as i32;
        let mono = ((left + right) / 2) as i16;
        mono_samples.push(mono);
    }

    AudioFrame {
        samples: mono_samples,
        sample_rate: frame.sample_rate,
        channels: 1,
        timestamp_ms: frame.timestamp_ms,
        source: frame.source,
    }
}

#[tokio::main]
async fn main() -> Result<()> {
    tracing_subscriber::fmt::init();

    info!("ğŸ™ï¸  Starting live recording with real-time transcription");

    // 1. Connect to NATS
    let meeting_id = format!("live-test-{}", chrono::Utc::now().timestamp());
    let nats = NatsClient::connect("nats://localhost:4222", meeting_id.clone()).await?;
    info!("âœ… Connected to NATS (meeting: {})", meeting_id);

    // 2. Subscribe to transcripts
    let mut subscriber = nats.subscribe_transcripts().await?;
    info!("âœ… Subscribed to transcripts");

    // 3. Create macOS audio backend
    // ScreenCaptureKit captures at 48kHz stereo (Systemâ†’Left, Micâ†’Right)
    // Swift handles the mixing with zero-fill for silent sources
    let backend_config = AudioBackendConfig {
        target_sample_rate: 48000,  // Native macOS rate (will downsample to 16kHz)
        target_channels: 2,          // Stereo (Systemâ†’L, Micâ†’R)
        buffer_duration_ms: 100,
    };
    let mut backend = AudioBackendFactory::create(AudioSource::System, backend_config)?;
    info!("âœ… Audio backend ready: ScreenCaptureKit (48kHz stereo â†’ 16kHz mono)");
    info!("   System audio â†’ LEFT channel");
    info!("   Microphone â†’ RIGHT channel");

    // 4. Spawn transcript listener task
    let stop_flag = Arc::new(AtomicBool::new(false));
    let stop_flag_clone = stop_flag.clone();

    let transcript_handle = tokio::spawn(async move {
        info!("ğŸ“ Listening for transcripts...");
        let mut transcript_count = 0;

        loop {
            match timeout(Duration::from_millis(500), subscriber.next()).await {
                Ok(Some(msg)) => {
                    if let Ok(transcript) = serde_json::from_slice::<TranscriptMessage>(&msg.payload) {
                        transcript_count += 1;
                        let conf_str = transcript
                            .confidence
                            .map(|c| format!("{:.2}%", c * 100.0))
                            .unwrap_or_else(|| "N/A".to_string());

                        let status = if transcript.partial { "PARTIAL" } else { "FINAL  " };

                        info!(
                            "ğŸ“ [{}] #{}: \"{}\" (confidence: {})",
                            status, transcript_count, transcript.text, conf_str
                        );
                    }
                }
                Ok(None) => {
                    info!("â¹ï¸  Transcript stream closed");
                    break;
                }
                Err(_) => {
                    // Timeout - check if we should stop
                    if stop_flag_clone.load(Ordering::Relaxed) {
                        info!("ğŸ›‘ Stop signal received in transcript listener");
                        break;
                    }
                }
            }
        }

        info!("âœ… Received {} transcripts total", transcript_count);
    });

    // 5. Start capturing audio
    info!("");
    info!("ğŸ¤ Starting audio capture for 15 seconds...");
    info!("ğŸ’¬ Speak into your microphone AND/OR play system audio!");
    info!("");

    let audio_rx = backend.start().await?;
    let start_time = tokio::time::Instant::now();
    let recording_duration = Duration::from_secs(15);

    // 6. Process frames: downsample and publish to NATS
    let mut chunk_index = 0;
    let mut last_pcm_bytes: Vec<u8> = Vec::new();
    let mut last_sample_rate = 16000;
    let mut last_channels = 2;

    tokio::pin!(audio_rx);
    'outer: loop {
        // Check if we've exceeded recording duration
        if start_time.elapsed() >= recording_duration {
            info!("â° Recording duration reached");
            break 'outer;
        }

        // Try to receive a frame with timeout
        match tokio::time::timeout(Duration::from_millis(100), audio_rx.recv()).await {
            Ok(Some(frame)) => {
                // Downsample from 48kHz stereo to 16kHz stereo
                let downsampled = downsample_frame(frame, 16000);

                // Convert from stereo to mono (Whisper expects mono)
                let mono = stereo_to_mono(downsampled);

                // Convert samples to bytes
                let pcm_bytes: Vec<u8> = mono
                    .samples
                    .iter()
                    .flat_map(|&s| s.to_le_bytes())
                    .collect();

                // Store for potential final frame
                last_pcm_bytes = pcm_bytes.clone();
                last_sample_rate = mono.sample_rate;
                last_channels = mono.channels;

                // Publish to NATS for transcription
                nats.publish_audio_frame(
                    &pcm_bytes,
                    mono.sample_rate,
                    mono.channels,
                    chunk_index,
                    false, // Not final yet
                )
                .await?;

                if chunk_index % 10 == 0 {
                    info!(
                        "ğŸ“¤ Published frame {} ({:.1}s elapsed)",
                        chunk_index,
                        start_time.elapsed().as_secs_f32()
                    );
                }

                chunk_index += 1;
            }
            Ok(None) => {
                // Channel closed - audio capture stopped
                break 'outer;
            }
            Err(_) => {
                // Timeout - continue waiting for frames
            }
        }
    }

    // 7. Send final frame marker to trigger transcription
    if !last_pcm_bytes.is_empty() {
        info!("ğŸ“¤ Sending final frame marker");
        nats.publish_audio_frame(
            &last_pcm_bytes,
            last_sample_rate,
            last_channels,
            chunk_index,
            true, // This is the final frame
        )
        .await?;
    }

    // 8. Stop backend
    backend.stop().await?;
    info!("â¹ï¸  Audio capture stopped");

    // 9. Wait for final transcripts
    info!("â³ Waiting for final transcripts (5s)...");
    sleep(Duration::from_secs(5)).await;

    // Signal transcript listener to stop
    stop_flag.store(true, Ordering::Relaxed);

    // Wait for transcript listener to finish
    match timeout(Duration::from_secs(2), transcript_handle).await {
        Ok(Ok(_)) => info!("âœ… Transcript listener completed"),
        Ok(Err(e)) => info!("âŒ Transcript listener error: {}", e),
        Err(_) => info!("â±ï¸  Transcript listener timeout"),
    }

    info!("");
    info!("ğŸ Live recording test complete!");
    info!("ğŸ“Š Total frames published: {}", chunk_index);

    Ok(())
}
